{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batch_data_preprocessors import get_batch_data_preprocessor_class\n",
    "from samplers import SegmentSampler\n",
    "from losses import get_loss_function\n",
    "from lightning_modules import LitSourceSeparation\n",
    "from lr_schedulers import get_lr_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.plugins import DDPPlugin\n",
    "import torch\n",
    "from data_modules import DataModule, Dataset\n",
    "\n",
    "# from bytesep.callbacks import get_callbacks\n",
    "# from bytesep.data.augmentors import Augmentor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "from functools import partial\n",
    "from typing import Dict, List, NoReturn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dirs(\n",
    "    workspace: str,\n",
    "    task_name: str,\n",
    "    filename: str,\n",
    "    config_yaml: str,\n",
    "    gpus: int,\n",
    ") -> List[str]:\n",
    "    r\"\"\"Get directory paths.\n",
    "    Args:\n",
    "        workspace: str\n",
    "        task_name, str, e.g., 'musdb18'\n",
    "        filenmae: str\n",
    "        config_yaml: str\n",
    "        gpus: int, e.g., 0 for cpu and 8 for training with 8 gpu cards\n",
    "    Returns:\n",
    "        checkpoints_dir: str\n",
    "        logs_dir: str\n",
    "        logger: pl.loggers.TensorBoardLogger\n",
    "        statistics_path: str\n",
    "    \"\"\"\n",
    "\n",
    "    # save checkpoints dir\n",
    "    checkpoints_dir = os.path.join(\n",
    "        workspace,\n",
    "        \"checkpoints\",\n",
    "        task_name,\n",
    "        filename,\n",
    "        \"config={},gpus={}\".format(pathlib.Path(config_yaml).stem, gpus),\n",
    "    )\n",
    "    os.makedirs(checkpoints_dir, exist_ok=True)\n",
    "\n",
    "    # logs dir\n",
    "    logs_dir = os.path.join(\n",
    "        workspace,\n",
    "        \"logs\",\n",
    "        task_name,\n",
    "        filename,\n",
    "        \"config={},gpus={}\".format(pathlib.Path(config_yaml).stem, gpus),\n",
    "    )\n",
    "    os.makedirs(logs_dir, exist_ok=True)\n",
    "\n",
    "    # loggings\n",
    "    create_logging(logs_dir, filemode='w')\n",
    "    logging.info(args)\n",
    "\n",
    "    # tensorboard logs dir\n",
    "    tb_logs_dir = os.path.join(workspace, \"tensorboard_logs\")\n",
    "    os.makedirs(tb_logs_dir, exist_ok=True)\n",
    "\n",
    "    experiment_name = os.path.join(task_name, filename, pathlib.Path(config_yaml).stem)\n",
    "    logger = pl.loggers.TensorBoardLogger(save_dir=tb_logs_dir, name=experiment_name)\n",
    "\n",
    "    # statistics path\n",
    "    statistics_path = os.path.join(\n",
    "        workspace,\n",
    "        \"statistics\",\n",
    "        task_name,\n",
    "        filename,\n",
    "        \"config={},gpus={}\".format(pathlib.Path(config_yaml).stem, gpus),\n",
    "        \"statistics.pkl\",\n",
    "    )\n",
    "    os.makedirs(os.path.dirname(statistics_path), exist_ok=True)\n",
    "\n",
    "    return checkpoints_dir, logs_dir, logger, statistics_path\n",
    "\n",
    "\n",
    "def get_data_module(\n",
    "    workspace: str,\n",
    "    config_yaml: str,\n",
    "    num_workers: int,\n",
    "    distributed: bool,\n",
    ") -> DataModule:\n",
    "    r\"\"\"Create data_module. Here is an example to fetch a mini-batch:\n",
    "    code-block:: python\n",
    "        data_module.setup()\n",
    "        for batch_data_dict in data_module.train_dataloader():\n",
    "            print(batch_data_dict.keys())\n",
    "            break\n",
    "    Args:\n",
    "        workspace: str\n",
    "        config_yaml: str\n",
    "        num_workers: int, e.g., 0 for non-parallel and 8 for using cpu cores\n",
    "            for preparing data in parallel\n",
    "        distributed: bool\n",
    "    Returns:\n",
    "        data_module: DataModule\n",
    "    \"\"\"\n",
    "    configs = read_yaml(config_yaml)\n",
    "    input_source_types = configs['train']['input_source_types']\n",
    "    target_source_types = configs['train']['target_source_types']\n",
    "    paired_input_target_data = configs['train']['paired_input_target_data']\n",
    "    indexes_dict_path = os.path.join(workspace, configs['train']['indexes_dict_path'])\n",
    "    sample_rate = configs['train']['sample_rate']\n",
    "    input_channels = configs['train']['input_channels']\n",
    "    segment_seconds = configs['train']['segment_seconds']\n",
    "    augmentations = configs['train']['augmentations']\n",
    "    batch_size = configs['train']['batch_size']\n",
    "    steps_per_epoch = configs['train']['steps_per_epoch']\n",
    "\n",
    "    segment_samples = int(segment_seconds * sample_rate)\n",
    "\n",
    "    if paired_input_target_data:\n",
    "        assert (\n",
    "            augmentations['remixing_sources'] is False\n",
    "        ), \"Must set remixing_sources to False if input and target data are paired.\"\n",
    "\n",
    "    ex_segment_samples = get_pitch_shifted_segment_samples(\n",
    "        segment_samples=segment_samples,\n",
    "        augmentations=augmentations,\n",
    "    )\n",
    "\n",
    "    # sampler\n",
    "    train_sampler = SegmentSampler(\n",
    "        indexes_dict_path=indexes_dict_path,\n",
    "        input_source_types=input_source_types,\n",
    "        target_source_types=target_source_types,\n",
    "        segment_samples=ex_segment_samples,\n",
    "        remixing_sources=augmentations['remixing_sources'],\n",
    "        mixaudio_dict=augmentations['mixaudio'],\n",
    "        batch_size=batch_size,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "    )\n",
    "\n",
    "    # augmentor\n",
    "    # augmentor = Augmentor(augmentations=augmentations)\n",
    "\n",
    "    # dataset\n",
    "    train_dataset = Dataset(\n",
    "        input_source_types=input_source_types,\n",
    "        target_source_types=target_source_types,\n",
    "        paired_input_target_data=paired_input_target_data,\n",
    "        input_channels=input_channels,\n",
    "        # augmentor=augmentor,\n",
    "        segment_samples=segment_samples,\n",
    "    )\n",
    "\n",
    "    # data module\n",
    "    data_module = DataModule(\n",
    "        train_sampler=train_sampler,\n",
    "        train_dataset=train_dataset,\n",
    "        num_workers=num_workers,\n",
    "        distributed=distributed,\n",
    "    )\n",
    "\n",
    "    return data_module\n",
    "\n",
    "\n",
    "def get_pitch_shifted_segment_samples(segment_samples: int, augmentations: Dict) -> int:\n",
    "    r\"\"\"Get new segment samples depending on maximum pitch shift.\n",
    "    Args:\n",
    "        segment_samples: int\n",
    "        augmentations: Dict\n",
    "    Returns:\n",
    "        ex_segment_samples: int\n",
    "    \"\"\"\n",
    "\n",
    "    if 'pitch_shift' not in augmentations.keys():\n",
    "        return segment_samples\n",
    "\n",
    "    else:\n",
    "        pitch_shift_dict = augmentations['pitch_shift']\n",
    "        source_types = pitch_shift_dict.keys()\n",
    "\n",
    "    max_pitch_shift = max(\n",
    "        [pitch_shift_dict[source_type] for source_type in source_types]\n",
    "    )\n",
    "\n",
    "    ex_segment_samples = int(segment_samples * get_pitch_shift_factor(max_pitch_shift))\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] {train} ...\n",
      "ipykernel_launcher.py: error: argument mode: invalid choice: '--f=\"c:\\\\Users\\\\Eugene Chen\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v2-14320hJqpQ1XEiuhJ.json\"' (choose from 'train')\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2288.0_x64__qbz5n2kfra8p0\\lib\\argparse.py:1859\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1858\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1859\u001b[0m     namespace, args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_known_args(args, namespace)\n\u001b[0;32m   1860\u001b[0m \u001b[39mexcept\u001b[39;00m ArgumentError:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2288.0_x64__qbz5n2kfra8p0\\lib\\argparse.py:2071\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args\u001b[1;34m(self, arg_strings, namespace)\u001b[0m\n\u001b[0;32m   2070\u001b[0m \u001b[39m# consume any positionals following the last Optional\u001b[39;00m\n\u001b[1;32m-> 2071\u001b[0m stop_index \u001b[39m=\u001b[39m consume_positionals(start_index)\n\u001b[0;32m   2073\u001b[0m \u001b[39m# if we didn't consume all the argument strings, there were extras\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2288.0_x64__qbz5n2kfra8p0\\lib\\argparse.py:2027\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args.<locals>.consume_positionals\u001b[1;34m(start_index)\u001b[0m\n\u001b[0;32m   2026\u001b[0m     start_index \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m arg_count\n\u001b[1;32m-> 2027\u001b[0m     take_action(action, args)\n\u001b[0;32m   2029\u001b[0m \u001b[39m# slice off the Positionals that we just parsed and return the\u001b[39;00m\n\u001b[0;32m   2030\u001b[0m \u001b[39m# index at which the Positionals' string args stopped\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2288.0_x64__qbz5n2kfra8p0\\lib\\argparse.py:1920\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args.<locals>.take_action\u001b[1;34m(action, argument_strings, option_string)\u001b[0m\n\u001b[0;32m   1919\u001b[0m seen_actions\u001b[39m.\u001b[39madd(action)\n\u001b[1;32m-> 1920\u001b[0m argument_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_values(action, argument_strings)\n\u001b[0;32m   1922\u001b[0m \u001b[39m# error if this argument is not allowed with other previously\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[39m# seen arguments, assuming that actions that use the default\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[39m# value don't really count as \"present\"\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2288.0_x64__qbz5n2kfra8p0\\lib\\argparse.py:2461\u001b[0m, in \u001b[0;36mArgumentParser._get_values\u001b[1;34m(self, action, arg_strings)\u001b[0m\n\u001b[0;32m   2460\u001b[0m     value \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_value(action, v) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m arg_strings]\n\u001b[1;32m-> 2461\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_value(action, value[\u001b[39m0\u001b[39;49m])\n\u001b[0;32m   2463\u001b[0m \u001b[39m# SUPPRESS argument does not put anything in the namespace\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2288.0_x64__qbz5n2kfra8p0\\lib\\argparse.py:2508\u001b[0m, in \u001b[0;36mArgumentParser._check_value\u001b[1;34m(self, action, value)\u001b[0m\n\u001b[0;32m   2507\u001b[0m msg \u001b[39m=\u001b[39m _(\u001b[39m'\u001b[39m\u001b[39minvalid choice: \u001b[39m\u001b[39m%(value)r\u001b[39;00m\u001b[39m (choose from \u001b[39m\u001b[39m%(choices)s\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 2508\u001b[0m \u001b[39mraise\u001b[39;00m ArgumentError(action, msg \u001b[39m%\u001b[39m args)\n",
      "\u001b[1;31mArgumentError\u001b[0m: argument mode: invalid choice: '--f=\"c:\\\\Users\\\\Eugene Chen\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v2-14320hJqpQ1XEiuhJ.json\"' (choose from 'train')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn [51], line 143\u001b[0m\n\u001b[0;32m    136\u001b[0m parser_train\u001b[39m.\u001b[39madd_argument(\n\u001b[0;32m    137\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m--config_yaml\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    138\u001b[0m     \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m,\n\u001b[0;32m    139\u001b[0m     required\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    140\u001b[0m     help\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPath of config file for training.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    141\u001b[0m )\n\u001b[1;32m--> 143\u001b[0m args \u001b[39m=\u001b[39m parser\u001b[39m.\u001b[39;49mparse_args()\n\u001b[0;32m    144\u001b[0m args\u001b[39m.\u001b[39mfilename \u001b[39m=\u001b[39m pathlib\u001b[39m.\u001b[39mPath(\u001b[39m__file__\u001b[39m)\u001b[39m.\u001b[39mstem\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2288.0_x64__qbz5n2kfra8p0\\lib\\argparse.py:1826\u001b[0m, in \u001b[0;36mArgumentParser.parse_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1825\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse_args\u001b[39m(\u001b[39mself\u001b[39m, args\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, namespace\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> 1826\u001b[0m     args, argv \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse_known_args(args, namespace)\n\u001b[0;32m   1827\u001b[0m     \u001b[39mif\u001b[39;00m argv:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2288.0_x64__qbz5n2kfra8p0\\lib\\argparse.py:1862\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1861\u001b[0m         err \u001b[39m=\u001b[39m _sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m1\u001b[39m]\n\u001b[1;32m-> 1862\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror(\u001b[39mstr\u001b[39;49m(err))\n\u001b[0;32m   1863\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2288.0_x64__qbz5n2kfra8p0\\lib\\argparse.py:2583\u001b[0m, in \u001b[0;36mArgumentParser.error\u001b[1;34m(self, message)\u001b[0m\n\u001b[0;32m   2582\u001b[0m args \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mprog\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprog, \u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m: message}\n\u001b[1;32m-> 2583\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexit(\u001b[39m2\u001b[39;49m, _(\u001b[39m'\u001b[39;49m\u001b[39m%(prog)s\u001b[39;49;00m\u001b[39m: error: \u001b[39;49m\u001b[39m%(message)s\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m) \u001b[39m%\u001b[39;49m args)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2288.0_x64__qbz5n2kfra8p0\\lib\\argparse.py:2570\u001b[0m, in \u001b[0;36mArgumentParser.exit\u001b[1;34m(self, status, message)\u001b[0m\n\u001b[0;32m   2569\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_print_message(message, _sys\u001b[39m.\u001b[39mstderr)\n\u001b[1;32m-> 2570\u001b[0m _sys\u001b[39m.\u001b[39;49mexit(status)\n",
      "\u001b[1;31mSystemExit\u001b[0m: 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Eugene Chen\\Desktop\\UNI\\deepLearning\\Project\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2042\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2039\u001b[0m \u001b[39mif\u001b[39;00m exception_only:\n\u001b[0;32m   2040\u001b[0m     stb \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mAn exception has occurred, use \u001b[39m\u001b[39m%\u001b[39m\u001b[39mtb to see \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   2041\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mthe full traceback.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m]\n\u001b[1;32m-> 2042\u001b[0m     stb\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mInteractiveTB\u001b[39m.\u001b[39;49mget_exception_only(etype,\n\u001b[0;32m   2043\u001b[0m                                                      value))\n\u001b[0;32m   2044\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2045\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   2046\u001b[0m         \u001b[39m# Exception classes can customise their traceback - we\u001b[39;00m\n\u001b[0;32m   2047\u001b[0m         \u001b[39m# use this in IPython.parallel for exceptions occurring\u001b[39;00m\n\u001b[0;32m   2048\u001b[0m         \u001b[39m# in the engines. This should return a list of strings.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Eugene Chen\\Desktop\\UNI\\deepLearning\\Project\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py:579\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_exception_only\u001b[39m(\u001b[39mself\u001b[39m, etype, value):\n\u001b[0;32m    572\u001b[0m     \u001b[39m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \n\u001b[0;32m    574\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[39m    value : exception value\u001b[39;00m\n\u001b[0;32m    578\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 579\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39;49mstructured_traceback(\u001b[39mself\u001b[39;49m, etype, value)\n",
      "File \u001b[1;32mc:\\Users\\Eugene Chen\\Desktop\\UNI\\deepLearning\\Project\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py:446\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    443\u001b[0m     chained_exc_ids\u001b[39m.\u001b[39madd(\u001b[39mid\u001b[39m(exception[\u001b[39m1\u001b[39m]))\n\u001b[0;32m    444\u001b[0m     chained_exceptions_tb_offset \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    445\u001b[0m     out_list \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 446\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m    447\u001b[0m             etype, evalue, (etb, chained_exc_ids),\n\u001b[0;32m    448\u001b[0m             chained_exceptions_tb_offset, context)\n\u001b[0;32m    449\u001b[0m         \u001b[39m+\u001b[39m chained_exception_message\n\u001b[0;32m    450\u001b[0m         \u001b[39m+\u001b[39m out_list)\n\u001b[0;32m    452\u001b[0m \u001b[39mreturn\u001b[39;00m out_list\n",
      "File \u001b[1;32mc:\\Users\\Eugene Chen\\Desktop\\UNI\\deepLearning\\Project\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py:1112\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1110\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1111\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtb \u001b[39m=\u001b[39m tb\n\u001b[1;32m-> 1112\u001b[0m \u001b[39mreturn\u001b[39;00m FormattedTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m   1113\u001b[0m     \u001b[39mself\u001b[39;49m, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "File \u001b[1;32mc:\\Users\\Eugene Chen\\Desktop\\UNI\\deepLearning\\Project\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py:1006\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1003\u001b[0m mode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode\n\u001b[0;32m   1004\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose_modes:\n\u001b[0;32m   1005\u001b[0m     \u001b[39m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[1;32m-> 1006\u001b[0m     \u001b[39mreturn\u001b[39;00m VerboseTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m   1007\u001b[0m         \u001b[39mself\u001b[39;49m, etype, value, tb, tb_offset, number_of_lines_of_context\n\u001b[0;32m   1008\u001b[0m     )\n\u001b[0;32m   1009\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mMinimal\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m   1010\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39mget_exception_only(\u001b[39mself\u001b[39m, etype, value)\n",
      "File \u001b[1;32mc:\\Users\\Eugene Chen\\Desktop\\UNI\\deepLearning\\Project\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py:859\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m    850\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstructured_traceback\u001b[39m(\n\u001b[0;32m    851\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    852\u001b[0m     etype: \u001b[39mtype\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    856\u001b[0m     number_of_lines_of_context: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m,\n\u001b[0;32m    857\u001b[0m ):\n\u001b[0;32m    858\u001b[0m     \u001b[39m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m     formatted_exception \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m    860\u001b[0m                                                            tb_offset)\n\u001b[0;32m    862\u001b[0m     colors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mColors  \u001b[39m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[0;32m    863\u001b[0m     colorsnormal \u001b[39m=\u001b[39m colors\u001b[39m.\u001b[39mNormal  \u001b[39m# used a lot\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Eugene Chen\\Desktop\\UNI\\deepLearning\\Project\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py:793\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(tb_offset, \u001b[39mint\u001b[39m)\n\u001b[0;32m    791\u001b[0m head \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_header(etype, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlong_header)\n\u001b[0;32m    792\u001b[0m records \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 793\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_records(etb, number_of_lines_of_context, tb_offset) \u001b[39mif\u001b[39;00m etb \u001b[39melse\u001b[39;00m []\n\u001b[0;32m    794\u001b[0m )\n\u001b[0;32m    796\u001b[0m frames \u001b[39m=\u001b[39m []\n\u001b[0;32m    797\u001b[0m skipped \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Eugene Chen\\Desktop\\UNI\\deepLearning\\Project\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py:848\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[1;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m    842\u001b[0m     formatter \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    843\u001b[0m options \u001b[39m=\u001b[39m stack_data\u001b[39m.\u001b[39mOptions(\n\u001b[0;32m    844\u001b[0m     before\u001b[39m=\u001b[39mbefore,\n\u001b[0;32m    845\u001b[0m     after\u001b[39m=\u001b[39mafter,\n\u001b[0;32m    846\u001b[0m     pygments_formatter\u001b[39m=\u001b[39mformatter,\n\u001b[0;32m    847\u001b[0m )\n\u001b[1;32m--> 848\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(stack_data\u001b[39m.\u001b[39;49mFrameInfo\u001b[39m.\u001b[39;49mstack_data(etb, options\u001b[39m=\u001b[39;49moptions))[tb_offset:]\n",
      "File \u001b[1;32mc:\\Users\\Eugene Chen\\Desktop\\UNI\\deepLearning\\Project\\venv\\lib\\site-packages\\stack_data\\core.py:564\u001b[0m, in \u001b[0;36mFrameInfo.stack_data\u001b[1;34m(cls, frame_or_tb, options, collapse_repeated_frames)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    549\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstack_data\u001b[39m(\n\u001b[0;32m    550\u001b[0m         \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    554\u001b[0m         collapse_repeated_frames: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    555\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Union[\u001b[39m'\u001b[39m\u001b[39mFrameInfo\u001b[39m\u001b[39m'\u001b[39m, RepeatedFrames]]:\n\u001b[0;32m    556\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    557\u001b[0m \u001b[39m    An iterator of FrameInfo and RepeatedFrames objects representing\u001b[39;00m\n\u001b[0;32m    558\u001b[0m \u001b[39m    a full traceback or stack. Similar consecutive frames are collapsed into RepeatedFrames\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[39m    and optionally an Options object to configure.\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 564\u001b[0m     stack \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(iter_stack(frame_or_tb))\n\u001b[0;32m    566\u001b[0m     \u001b[39m# Reverse the stack from a frame so that it's in the same order\u001b[39;00m\n\u001b[0;32m    567\u001b[0m     \u001b[39m# as the order from a traceback, which is the order of a printed\u001b[39;00m\n\u001b[0;32m    568\u001b[0m     \u001b[39m# traceback when read top to bottom (most recent call last)\u001b[39;00m\n\u001b[0;32m    569\u001b[0m     \u001b[39mif\u001b[39;00m is_frame(frame_or_tb):\n",
      "File \u001b[1;32mc:\\Users\\Eugene Chen\\Desktop\\UNI\\deepLearning\\Project\\venv\\lib\\site-packages\\stack_data\\utils.py:97\u001b[0m, in \u001b[0;36miter_stack\u001b[1;34m(frame_or_tb)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[39mwhile\u001b[39;00m frame_or_tb:\n\u001b[0;32m     96\u001b[0m     \u001b[39myield\u001b[39;00m frame_or_tb\n\u001b[1;32m---> 97\u001b[0m     \u001b[39mif\u001b[39;00m is_frame(frame_or_tb):\n\u001b[0;32m     98\u001b[0m         frame_or_tb \u001b[39m=\u001b[39m frame_or_tb\u001b[39m.\u001b[39mf_back\n\u001b[0;32m     99\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Eugene Chen\\Desktop\\UNI\\deepLearning\\Project\\venv\\lib\\site-packages\\stack_data\\utils.py:90\u001b[0m, in \u001b[0;36mis_frame\u001b[1;34m(frame_or_tb)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_frame\u001b[39m(frame_or_tb: Union[FrameType, TracebackType]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m---> 90\u001b[0m     assert_(\u001b[39misinstance\u001b[39;49m(frame_or_tb, (types\u001b[39m.\u001b[39;49mFrameType, types\u001b[39m.\u001b[39;49mTracebackType)))\n\u001b[0;32m     91\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39misinstance\u001b[39m(frame_or_tb, (types\u001b[39m.\u001b[39mFrameType,))\n",
      "File \u001b[1;32mc:\\Users\\Eugene Chen\\Desktop\\UNI\\deepLearning\\Project\\venv\\lib\\site-packages\\stack_data\\utils.py:171\u001b[0m, in \u001b[0;36massert_\u001b[1;34m(condition, error)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(error, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    170\u001b[0m     error \u001b[39m=\u001b[39m \u001b[39mAssertionError\u001b[39;00m(error)\n\u001b[1;32m--> 171\u001b[0m \u001b[39mraise\u001b[39;00m error\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(args) -> NoReturn:\n",
    "    r\"\"\"Train & evaluate and save checkpoints.\n",
    "    Args:\n",
    "        workspace: str, directory of workspace\n",
    "        gpus: int\n",
    "        config_yaml: str, path of config file for training\n",
    "    \"\"\"\n",
    "\n",
    "    # arugments & parameters\n",
    "    workspace = args.workspace\n",
    "    gpus = args.gpus\n",
    "    config_yaml = args.config_yaml\n",
    "    filename = args.filename\n",
    "\n",
    "    num_workers = 8\n",
    "    distributed = True if gpus > 1 else False\n",
    "    evaluate_device = \"cuda\" if gpus > 0 else \"cpu\"\n",
    "\n",
    "    # Read config file.\n",
    "    configs = read_yaml(config_yaml)\n",
    "    check_configs_gramma(configs)\n",
    "    task_name = configs['task_name']\n",
    "    input_source_types = configs['train']['input_source_types']\n",
    "    target_source_types = configs['train']['target_source_types']\n",
    "    input_channels = configs['train']['input_channels']\n",
    "    output_channels = configs['train']['output_channels']\n",
    "    batch_data_preprocessor_type = configs['train']['batch_data_preprocessor']\n",
    "    model_type = configs['train']['model_type']\n",
    "    loss_type = configs['train']['loss_type']\n",
    "    optimizer_type = configs['train']['optimizer_type']\n",
    "    learning_rate = float(configs['train']['learning_rate'])\n",
    "    precision = configs['train']['precision']\n",
    "    early_stop_steps = configs['train']['early_stop_steps']\n",
    "    warm_up_steps = configs['train']['warm_up_steps']\n",
    "    reduce_lr_steps = configs['train']['reduce_lr_steps']\n",
    "    resume_checkpoint_path = configs['train']['resume_checkpoint_path']\n",
    "\n",
    "    target_sources_num = len(target_source_types)\n",
    "\n",
    "    # paths\n",
    "    checkpoints_dir, logs_dir, logger, statistics_path = get_dirs(\n",
    "        workspace, task_name, filename, config_yaml, gpus\n",
    "    )\n",
    "\n",
    "    # training data module\n",
    "    data_module = get_data_module(\n",
    "        workspace=workspace,\n",
    "        config_yaml=config_yaml,\n",
    "        num_workers=num_workers,\n",
    "        distributed=distributed,\n",
    "    )\n",
    "\n",
    "    # batch data preprocessor\n",
    "    BatchDataPreprocessor = get_batch_data_preprocessor_class(\n",
    "        batch_data_preprocessor_type=batch_data_preprocessor_type\n",
    "    )\n",
    "\n",
    "    batch_data_preprocessor = BatchDataPreprocessor(\n",
    "        input_source_types=input_source_types, target_source_types=target_source_types\n",
    "    )\n",
    "\n",
    "    # model\n",
    "    Model = get_model_class(model_type=model_type)\n",
    "    model = Model(\n",
    "        input_channels=input_channels,\n",
    "        output_channels=output_channels,\n",
    "        target_sources_num=target_sources_num,\n",
    "    )\n",
    "\n",
    "    if resume_checkpoint_path:\n",
    "        checkpoint = torch.load(resume_checkpoint_path)\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        logging.info(\n",
    "            \"Load pretrained checkpoint from {}\".format(resume_checkpoint_path)\n",
    "        )\n",
    "\n",
    "    # loss function\n",
    "    loss_function = get_loss_function(loss_type=loss_type)\n",
    "\n",
    "    # callbacks\n",
    "    # callbacks = get_callbacks(\n",
    "    #     task_name=task_name,\n",
    "    #     config_yaml=config_yaml,\n",
    "    #     workspace=workspace,\n",
    "    #     checkpoints_dir=checkpoints_dir,\n",
    "    #     statistics_path=statistics_path,\n",
    "    #     logger=logger,\n",
    "    #     model=model,\n",
    "    #     evaluate_device=evaluate_device,\n",
    "    # )\n",
    "    callbacks = []\n",
    "\n",
    "    # learning rate reduce function\n",
    "    lr_lambda = partial(\n",
    "        get_lr_lambda, warm_up_steps=warm_up_steps, reduce_lr_steps=reduce_lr_steps\n",
    "    )\n",
    "\n",
    "    # pytorch-lightning model\n",
    "    pl_model = LitSourceSeparation(\n",
    "        batch_data_preprocessor=batch_data_preprocessor,\n",
    "        model=model,\n",
    "        optimizer_type=optimizer_type,\n",
    "        loss_function=loss_function,\n",
    "        learning_rate=learning_rate,\n",
    "        lr_lambda=lr_lambda,\n",
    "    )\n",
    "\n",
    "    # trainer\n",
    "    trainer = pl.Trainer(\n",
    "        checkpoint_callback=False,\n",
    "        gpus=gpus,\n",
    "        callbacks=callbacks,\n",
    "        max_steps=early_stop_steps,\n",
    "        accelerator=\"ddp\",\n",
    "        sync_batchnorm=True,\n",
    "        precision=precision,\n",
    "        replace_sampler_ddp=False,\n",
    "        plugins=[DDPPlugin(find_unused_parameters=False)],\n",
    "        profiler='simple',\n",
    "    )\n",
    "\n",
    "    # Fit, evaluate, and save checkpoints.\n",
    "    trainer.fit(pl_model, data_module)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"\")\n",
    "    subparsers = parser.add_subparsers(dest=\"mode\")\n",
    "\n",
    "    parser_train = subparsers.add_parser(\"train\")\n",
    "    parser_train.add_argument(\n",
    "        \"--workspace\", type=str, required=True, help=\"Directory of workspace.\"\n",
    "    )\n",
    "    parser_train.add_argument(\"--gpus\", type=int, required=True)\n",
    "    parser_train.add_argument(\n",
    "        \"--config_yaml\",\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"Path of config file for training.\",\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    args.filename = pathlib.Path(__file__).stem\n",
    "\n",
    "    if args.mode == \"train\":\n",
    "        train(args)\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"Error argument!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a64d1171b83a0e26588b59fe61b6200c2d65e3b1ad302ff19640eea9a2f088d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
